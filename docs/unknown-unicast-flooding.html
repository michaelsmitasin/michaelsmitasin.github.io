<html>
<head>
<title>
SMITASIN/UNKNOWN-UNICAST-FLOODING
</title>
<link rel="stylesheet" type="text/css" href="../base.css" />
</head>
<body>
<div id="headblock">
<img src="../flag.png" height=32px width=50px>
<a href="../"><h1>SMITASIN</a>/<a href="../docs.html">DOCS</a>/<br>
Unknown Unicast Flooding</h1>
<br>
<h2>Originally: Unknown Unicast Floods with FreeBSD Aliases and Juniper Storm Control (EX series)</h2><br>
<hr>
</div>
<div id="textblock">
<h2>Preface</h2><br>
<p>
2020-12-26: I had originally posted this in November of 2014, just about a year and three months after having started work as a Network Engineer. I'm sure that the implementation specifics of FreeBSD aliases and Juniper storm control have changed since then, so this may no longer be relevant to modern installations, but I think the tale of troubleshooting is an interesting one, and this provides a peek into the perspective of an early-career Network Engineer. I've copied over the content as-is, with only reformatting to match my current site.
</p>
<hr>
<p> 
Hopefully this will be useful to other people who’ve also implemented <a href="http://www.juniper.net/techpubs/en_US/junos12.3/topics/concept/rate-limiting-storm-control-understanding.html">storm control on Juniper EX series switches (PDF)</a>. This has been tricky to locate, but I believe I now understand the root cause and have found a way to quickly and easily identify this specific situation (which seems like it could crop up easily). Why should you care if this is happening? Well, it could mean dropping a lot of traffic… but more about that later.
</p>
<p>
For several months we’ve been receiving syslog messages about storm control going into effect on the link between one of our Juniper EX4200 switches that is acting as a distribution switch for a decent sized building complex and its router:
<pre>
Nov 4 05:31:49 myswitchname eswd[1308]: %DAEMON-1-ESWD_ST_CTL_ERROR_IN_EFFECT: ae0.0: storm control in effect on the port
</pre>
</p>
<p>
My first inclination was to assume someone was causing a broadcast storm by introducing a loop, but this ended up being a bit more interesting of a problem. We run BPDU guard and storm control on downstream switches, so there are fewer situations where this could be due to a simple loop. Further, this was only being triggered on the uplink to the router, not any of the other nearly 20 downstream links to access layer switches.
</p>
<p>
Obviously, a packet capture was in order. We set up a monitor session on the router to mirror traffic on the 2x1GE port-channel to the EX4200 switches because the router’s located in a data center and it’s easy to rack mount a decently powerful capture box there. Here’s what it looked like:
<img src="../images/eswd_cap1.png"></img>
</p>
<p>
However, when filtering on eth.addr==ff:ff:ff:ff:ff:ff I noticed that broadcasts were not a significant portion of traffic. Capturing from a mirror port on the router wasn’t going to be enough… I had no way just looking at that capture to differentiate between “known” unicast traffic and “unknown” traffic (traffic destined for a MAC address not in the switch’s MAC address table)… I’d need more data.
</p>
<p class="footer">
2014-11-14
</p>
</div>
</body>
</html>
